<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Srijan Das</title>
  
  <meta name="author" content="Srijan Das">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Srijan Das</name>
              </p>
              <p>I am a Postdoctoral Associate at Stony Brook University. I am a member of the Robotics Lab in <a href="http://michaelryoo.com/">Michael Ryoo's</a> team.
              </p>
              <p>
                At SBU, I' am working on Video Representation Learning, and Robotic Vision. Before this, I completed my Ph.D. in Computer Science at INRIA, Sophia Antipolis, France under the supervision of <a href="http://www-sop.inria.fr/members/Francois.Bremond/">Francois Bremond</a> and <a href="http://www-sop.inria.fr/members/Monique.Thonnat/">Monique Thonnat</a>.
                My Ph.D. thesis is on <a href="https://hal.archives-ouvertes.fr/tel-02973812/document">¨Spatio-temporal attention mechanisms for Action Recognition¨</a> and click <a href="https://www.youtube.com/watch?v=HIsqMt9dA78">here</a> to watch my Defense Presentation.
                I did my Post-Grad in Computer Science from the <a href="https://www.nitrkl.ac.in/">National Institute of Technology (NIT), Rourkela</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:srijan.das@stonybrook.edu">Email</a> &nbsp/&nbsp
                <a href="data/srijan_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/srijan-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ZDTF5AEAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/srijandas07">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/srijandas07/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/srijan_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/srijan_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, deep learning, and image processing. I have been mostly working on video representation learning including spatio-temporal attention mechanisms, cross-modal attention mechanisms, cross-modal knowledge distillation, and self-supervised learning for applications like action classification in trimmed videos, temporal action detection in untrimmed videos, video retrieval, anaomaly detection, and deepfake detection. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="viewclr_stop()" onmouseover="viewclr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/viewclr.png' width="160">
              </div>
              <script type="text/javascript">
                function viewclr_start() {
                  document.getElementById('rawnerf_image').style.opacity = "1";
                }

                function rawnerf_stop() {
                  document.getElementById('viewclr_image').style.opacity = "0";
                }
                viewclr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.03905">
                <papertitle>ViewCLR: Learning Self-supervised Video Representation for Unseen Viewpoints</papertitle>
              </a>
              <br>
              <strong>Srijan Das</strong>, and Michael S. Ryoo
              <br>
							<em>Arxiv Pre-print</em>, December 2021
              <br>
              <a href="https://arxiv.org/abs/2112.03905">arXiv</a>
              <p></p>
              <p>
								A framework for learning self-supervised video representation that is invariant to unseen camera viewpoints.</p>
            </td>
          </tr>

        <tr onmouseout="mstct_stop()" onmouseover="mstct_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mstct.png' height=110px width=185px>
              </div>
              <script type="text/javascript">
                function mstct_start() {
                  document.getElementById('MSTCT').style.opacity = "1";
                }
                function mstct_stop() {
                  document.getElementById('MSTCT').style.opacity = "0";
                }
                mstct_stop()
              </script>
           </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <a href="https://arxiv.org/pdf/2112.03902.pdf">
                     <papertitle>MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection</papertitle>
               </a>
              <br>
              Rui Dai, <strong>Srijan Das</strong>, Kumara Kahatapitiya, Michael S. Ryoo, Francois Bremond.
              <br>
              <em>Arxiv Pre-print</em>, December 2021
              <br>
              <p> A ConvTransformer network that explores global and local temporal relations at multiple resolutions.</p>
            </td>
          </tr>

          <tr onmouseout="vpn++_stop()" onmouseover="vpn++_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">

                <img src='images/vpn++.png' height=150px width=200px>
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('vpn++_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('vpn++_image').style.opacity = "0";
                }
                vpn++_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.08141">
                <papertitle>VPN++: Rethinking Video-Pose embeddings for understanding Activities of Daily Living</papertitle>
              </a>
              <br>
              <strong>Srijan Das</strong>, Rui Dai, Di Yang, Francois Bremond,
              <br>
							<em>TPAMI</em>, 2021 (DOI: 10.1109/TPAMI.2021.3127885)
              <br>
              <a href="https://arxiv.org/abs/2105.08141">arXiv</a>
              /
              <a href="https://github.com/srijandas07/vpnplusplus">code</a>
              <p></p>
              <p>VPN++ is an extension of our VPN model (ECCV 2020). VPN++ hallucinates pose driven features while not requiring costly 3D Poses at inference.</p>
            </td>
          </tr> 

          <tr onmouseout="bmvc21_stop()" onmouseover="bmvc21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ctrn.png' height=145px width=185px>
              </div>
              <script type="text/javascript">
                function bmvc21_start() {
                  document.getElementById('bmvc21_image').style.opacity = "1";
                }
                function bmvc21_stop() {
                  document.getElementById('bmvc21_image').style.opacity = "0";
                }
                tsu_stop()
              </script>
           </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0133.html">
                     <papertitle>CTRN: Class Temporal Relational Network for Action Detection</papertitle>
               </a>
              <br>
              Rui Dai, <strong>Srijan Das</strong>, Francois Bremond.
              <br>
              <em> <!--The British Machine Vision Conference, 2021. -->
                <strong>BMVC 2021, Oral</strong></em>
              <br>
            </td>
          </tr>


					

          <tr onmouseout="urf_stop()" onmouseover="urf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='urf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/urf.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/urf.jpg' width="160">
              </div>
              <script type="text/javascript">
                function urf_start() {
                  document.getElementById('urf_image').style.opacity = "1";
                }

                function urf_stop() {
                  document.getElementById('urf_image').style.opacity = "0";
                }
                urf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://urban-radiance-fields.github.io/">
                <papertitle>Urban Radiance Fields</papertitle>
              </a>
              <br>
							<a href="http://www.krematas.com/">Konstantinos Rematas</a>,
							<a href="https://andrewhliu.github.io/">Andrew Liu</a>,
							<a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
							<strong>Jonathan T. Barron</strong>, <br>
							<a href="https://taiya.github.io/">Andrea Tagliasacchi</a>,
							<a href="https://www.cs.princeton.edu/~funk/">Tom Funkhouser</a>,
							<a href="https://sites.google.com/corp/view/vittoferrari"> Vittorio Ferrari</a>
              <br>
							<em>arXiv</em>, 2021
              <br>
              <a href="https://urban-radiance-fields.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2111.14643">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=qGlq5DZT6uc">video</a>
              <p></p>
              <p>
								Incorporating lidar and explicitly modeling the sky lets you reconstruct urban environments.</p>
            </td>
          </tr> 

	
  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='ddp_image'>
          <img src='images/ddp_after.jpg' width="160"></div>
        <img src='images/ddp_before.jpg' width="160">
      </div>
      <script type="text/javascript">
        function ddp_start() {
          document.getElementById('ddp_image').style.opacity = "1";
        }

        function ddp_stop() {
          document.getElementById('ddp_image').style.opacity = "0";
        }
        ddp_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2112.03288">
        <papertitle>Dense Depth Priors for Neural Radiance Fields from Sparse Input Views</papertitle>
      </a>
      <br>
			<a href="https://niessnerlab.org/members/barbara_roessle/profile.html">Barbara Roessle</a>,
			<strong>Jonathan T. Barron</strong>,
			<a href="https://bmild.github.io/">Ben Mildenhall</a>, 
			<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, 
			<a href="https://www.niessnerlab.org/">Matthias Nießner</a>
      <br>
			<em>Arxiv</em>, 2021
      <br>
      <a href="https://arxiv.org/abs/2112.03288">arXiv</a>
      /
      <a href="https://www.youtube.com/watch?v=zzkvvdcvksc">video</a>
      <p></p>
      <p>
      Dense depth completion techniques applied to freely-available sparse stereo data can improve NeRF reconstructions in low-data regimes.
      </p>
    </td>
  </tr>
	


        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        
</body>

</html>
